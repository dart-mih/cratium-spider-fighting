# -----------------------------------------------------------------------------
# Для main.py, vizualize.py, plot_graph.py.
# Параметры среды (её имя + максимальное число шагов, на которое она рассчитана).
ENV_NAME=Craftium/SpidersAttack-v0
MAX_EP_LEN=4000
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# Для main.py, vizualize.py.
# Количество фреймов последних, которые необходимо стакать в состоянии среды.
FRAME_STACK_SIZE=4
# Делать ли изображения черно-белыми.
GRAYSCALE=True
# Размер получаемого состояния среды.
OBS_W=64
OBS_H=64
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# Для main.py.
# Количество сред, которые запускаются параллельно для обучения.
# (Стоит учитывать, что каждая эпоха будет проходить для каждой среды и размер буфера увеличится кратно).
ENV_COUNT=4
# Максимальное количество шагов обучения (после скольки шагов обучения прекратится).
MAX_TRAIN_TIMESTEPS=512000
# Как часто будут обновляться веса PPO (минимальное число примеров в буфере).
# (Обычно стоит поставить побольше, так как чем больше в 1 наборе данных, тем эффективнее обучение на них,
# но нагрузка на GPU сильно возрастет).
UPDATE_MIN_SAMPLES=4000
# Как часто будут печататься средние награды в консоль (множитель к MAX_EP_LEN).
PRINT_FREQ_MULT=1.5
# Как часто будут печататься средние награды в csv файл для построения графиков (множитель к MAX_EP_LEN).
LOG_FREQ_MULT=1.0

# Количество раз, которое PPO будет обучаться на одних и тех же данных из буфера, после чего очистит буфер.
K_EPOCHS=20
# Коэффициент клипинга PPO (обычно изменяется в пределах 0.2 до 0.3).
# (Грубо говоря отвечает за то, насколько сильно PPO будет менять свои веса в ответ на данные из буфера)
# Чем больше клипинг, тем меньше меняет веса.
EPS_CLIP=0.2
# Множитель к будущим действиям, отвечающий за то, насколько модели важны долгосрочные выгоды перед краткосрочными.
# Ближе к 1 - важны долгосрочные выгоды. Ближе к 0 - важны краткосрочные выгоды.
GAMMA=0.99
# Скорость обучения актора (слишком маленькое - будет обучаться долго, слишком большое - перепрыгнет оптимальые веса).
# Актор - тот, кто совершает действия в среде.
LR_ACTOR=0.0003
# Скорость обучения критика (слишком маленькое - будет обучаться долго, слишком большое - перепрыгнет оптимальые веса).
# Критик - тот, кто оценивает, насколько хорошо то или иное действие.
LR_CRITIC=0.001

# С какой частотой (в шагах) сохранять текущие веса обученной модели.
SAVE_MODEL_FREQ=64000
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# Для vizualize.py.
# Путь к предобученным весам модели.
MODEL_WEIGHTS_PATH="checkpoints/Craftium-SpidersAttack-v0/PPO_Craftium-SpidersAttack-v0_1.pth"
# -----------------------------------------------------------------------------
